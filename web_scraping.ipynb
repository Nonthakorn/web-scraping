{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# นนทกร มาคีรี 60070144 assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get(\"http://www.it.kmitl.ac.th/~teerapong/news_archive/index.html\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_month = []\n",
    "for i in soup.find_all('a',href=True):  #เก็บ link แต่ละเดือนเข้า list\n",
    "    req_month = \"http://www.it.kmitl.ac.th/~teerapong/news_archive/\"+ i['href']\n",
    "    lst_month.append(req_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.it.kmitl.ac.th/~teerapong/news_archive/month-jan-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-feb-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-mar-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-apr-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-may-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-jun-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-jul-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-aug-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-sep-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-oct-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-nov-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/month-dec-2017.html',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/#',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/#',\n",
       " 'http://www.it.kmitl.ac.th/~teerapong/news_archive/#']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "วน loop แต่ละเดือนเพื่อเก็บค่า Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsttype = [] #สร้าง list มาเก็บค่า category\n",
    "for type_ in lst_month[0:12]: #เอาแค่ 12 item ในลิส(12 เดือน)\n",
    "    page_type = requests.get(type_)   # request แต่ละเดือน\n",
    "    soup_type = BeautifulSoup(page_type.text, 'html.parser')\n",
    "    for addtype in soup_type.find_all('td',{\"class\": \"category\"}): #loop ใน tag ที่เป็น category\n",
    "        lsttype.append(addtype.get_text().lstrip('\\xa0')) # strip ตัดคำ '\\xa0sport' ให้เหลือแค่ 'sport'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in lsttype:\n",
    "    if i == 'N/A':\n",
    "        lsttype.remove(i) # ตัดค่า N/A ออก\n",
    "file = open('datastore/category.txt','w',encoding='utf-8') #เรียกไฟล์ที่จะเก็บคือ category.txt\n",
    "for i in lsttype:\n",
    "    file.write(i+'\\n') #เขียน item ที่เป็น category ลงในไฟ category.txt และให้ขึ้นบรรทัดใหม่เมื่อจบ 1 loop\n",
    "file.close()\n",
    "len(lsttype) #ดูจำนวน category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstitem = [] #สร้าง list มาเพื่อเก็บ link ของแต่ละข่าว\n",
    "for i in lst_month[0:12]:\n",
    "    pages = requests.get(i)  # request แต่ละเดือน\n",
    "    soups = BeautifulSoup(pages.text, 'html.parser')\n",
    "    item = soups.find('tbody') \n",
    "    for j in item.find_all('a', href=True):  #วนลูปเก็บ link ข่าวทุกข่าว\n",
    "        req_item = \"http://www.it.kmitl.ac.th/~teerapong/news_archive/\"+ j['href']\n",
    "        lstitem.append(req_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "lstcontent = [] #สร้าง list เพื่อมาเก็บ text ข่าวทั้งหมด\n",
    "for i in lstitem: # วน loop แต่ละ link เพื่อเก็บตัว Body ของทุกข่าว\n",
    "    time.sleep(0.1)\n",
    "    page_content = requests.get(i) # request แต่ละ link ของข่าว\n",
    "    soup_content = BeautifulSoup(page_content.content, 'html.parser')\n",
    "    content = soup_content.find_all('p') #เอา tag p มาทั้งหมด\n",
    "    tmp = []\n",
    "    for j in content[1:-1:1]: #วน loop ใน tag p แต่ไม่เอาตัวแรกและตัวสุดท้าย\n",
    "        tmp.append(j.get_text()) #แปลง tag p ให้เป็น text\n",
    "    lstcontent.append(''.join(tmp)) #เนื่องจากใน 1 ข่าวมีหลาย tag p เลยใช้ .join เพื่อเอา text มาต่อกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('datastore/news.txt','w',encoding=\"utf-8\") #เรียกไฟล์ที่จะเก็บคือ news.txt\n",
    "for i in lstcontent:\n",
    "    file.writelines(i+'\\n') #เขียน item ที่เป็น text ของข่าว ลงในไฟ news.txt และให้ขึ้นบรรทัดใหม่เมื่อจบ 1 loop\n",
    "file.close()\n",
    "len(lstcontent) #ดูจำนวนข่าวทั้งหมด"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เรียก 2 ไฟล์คือ category และ news เพื่อเก็บเป็น X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sporting industry has come a long way since the ‘60s. It has carved out for itself a niche with its roots so deep that I cannot fathom the sports industry showing any sign of decline any time soon - or later.The reason can be found in this seemingly subtle difference - other industries have customers; the sporting industry has fans. Vivek Ranadivé, leader of the ownership group of the NBA’s Sacramento Kings, explained it beautifully, “Fans will paint their face purple, fans will evangelize. ... Every other CEO in every business is dying to be in our position — they’re dying to have fans.“While fan passion alone could almost certainly keep the industry going, leagues and sporting franchises have decided not to rest on their laurels. The last few years have seen the steady introduction of technology into the world of sports - amplifying fans’ appreciation of games, enhancing athletes’ public profiles and informing their training methods, even influencing how contests are waged.Also, digital technology in particular has helped to create an alternative source of revenue, besides the games themselves - corporate sponsorship. They achieved this by capitalizing on the ardor of their customer base - sorry, fan base.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"datastore/news.txt\",'r',encoding=\"utf8\")\n",
    "file_read = file.readlines() \n",
    "file.close()\n",
    "file_news = []\n",
    "for i in file_read:\n",
    "    file_news.append(i.rstrip('\\n')) #ตัด \\n ออก\n",
    "file_news[0] #ค้นหาเพื่อดูข่าวแรก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file2 = open(\"datastore/category.txt\",'r',encoding=\"utf8\")\n",
    "file_type = file2.readlines()\n",
    "file2.close()\n",
    "Y = []\n",
    "for i in file_type:\n",
    "    Y.append(i.rstrip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ใช้ Tfid ทำการถ่วงน้ำหนักและ stop word ตัดคำที่ไม่จำเป็นออก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",min_df = 5)\n",
    "X = vectorizer.fit_transform(file_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# สร้าง Model (naive bayes, decisiontree, knn)\n",
    "### ใช้ cross validation 10 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97902098 0.9858156  0.9858156  0.9929078  0.9787234  0.9858156\n",
      " 0.99285714 0.97142857 0.97142857 0.95714286]\n",
      "Accuracy naive bayes in cross validation : 0.980 (+/- 0.011)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score #import library ที่ใช้ให้การทำ cross validation\n",
    "model_nb = BernoulliNB(alpha=0.2)\n",
    "cv_naive = cross_val_score(model_nb, X, Y, cv=10)\n",
    "print(cv_naive)                                                         #ค่า accuracy ทั้ง 10 กลุ่มของ naive_bayes\n",
    "print(\"Accuracy naive bayes in cross validation : %0.3f (+/- %0.3f)\" % (cv_naive.mean(), cv_naive.std())) #แสดงค่าเฉลี่ยของ accuracy และค่า standard deviation ของ naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8951049  0.86524823 0.89361702 0.91489362 0.87943262 0.86524823\n",
      " 0.93571429 0.89285714 0.9        0.87857143]\n",
      "Accuracy decision tree in cross validation: 0.892 (+/- 0.021)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=1) \n",
    "cv_tree = cross_val_score(decision_tree, X, Y, cv=10)\n",
    "print(cv_tree)                                                                                    #ค่า accuracy ทั้ง 10 กลุ่มของ decistion tree\n",
    "print(\"Accuracy decision tree in cross validation: %0.3f (+/- %0.3f)\" % (cv_tree.mean(), cv_tree.std())) #แสดงค่าเฉลี่ยของ accuracy และค่า standard deviation ของ decistion tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97902098 0.97163121 0.9787234  0.97163121 0.95035461 0.96453901\n",
      " 0.96428571 0.96428571 0.98571429 0.94285714]\n",
      "Accuracy knn in cross validation: 0.967 (+/- 0.012)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=15)\n",
    "cv_knn = cross_val_score(neigh, X, Y, cv=10)\n",
    "print(cv_knn)                                                                                    #ค่า accuracy ทั้ง 10 กลุ่มของ knn\n",
    "print(\"Accuracy knn in cross validation: %0.3f (+/- %0.3f)\" % (cv_knn.mean(), cv_knn.std())) #แสดงค่าเฉลี่ยของ accuracy และค่า standard deviation ของ knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุปผล"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ผลลัพธ์ที่ได้จาก 3 model ข้างบน ทำให้สรุปผลได้ว่า โมเดล Naive Bayes ได้ค่า Acuuracy เฉลี่ยเท่ากับ 0.980 +/- 0.011 ซึ่งสูงสุดเมื่อเทียบกับอีก 2 โมเดล\n",
    "ทำให้บอกได้ว่าโมเดล Naive Bayes มีประสิทธิภาพในการจำแนกหมวดหมู่ข่าวจากบทความข่าวได้ดีที่สุด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
